{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f5fee260ff0f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2da96d54088b205",
   "metadata": {},
   "source": [
    "Model and Tokenizer (from HuggingFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e155e583f9e4e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, attn_implementation=\"eager\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54fc496def7f7a",
   "metadata": {},
   "source": [
    "For evaluation of Correctness of GSM8K (taken from the authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "48618d4ae6bfaf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the authors' code\n",
    "\n",
    "def _is_float(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def is_correct(target, ans):\n",
    "    if _is_float(target) and _is_float(ans):\n",
    "        if abs(float(target) - float(ans)) <= 1e-5:\n",
    "            return True\n",
    "    elif str(target) == str(ans):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb566adf7060eb5",
   "metadata": {},
   "source": [
    "For CoT-decoding (taken from GitHub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20d3f500b3346cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def calculate_confidence(logits: List[torch.Tensor], answer_ids: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the confidence score (Δ) as specified in the paper.\n",
    "\n",
    "    Args:\n",
    "        logits: List of logits for each decoding step\n",
    "        answer_ids: Tensor of token ids for the answer\n",
    "\n",
    "    Returns:\n",
    "        Confidence score (Δ)\n",
    "    \"\"\"\n",
    "    confidence_sum = 0.0\n",
    "    valid_tokens = 0\n",
    "    for t, token_id in enumerate(answer_ids):\n",
    "        if t >= len(logits):\n",
    "            break\n",
    "        token_logits = logits[t]\n",
    "        probs = torch.softmax(token_logits, dim=-1)\n",
    "        if probs.size(-1) > 1:\n",
    "            top_2_probs, _ = torch.topk(probs, min(2, probs.size(-1)))\n",
    "            if top_2_probs.size(-1) > 1:\n",
    "                confidence_sum += (top_2_probs[-1]\n",
    "                                   [0] - top_2_probs[-1][1]).item()\n",
    "            else:\n",
    "                confidence_sum += 1.0  # Max confidence if there's only one token\n",
    "        else:\n",
    "            confidence_sum += 1.0  # Max confidence if there's only one token\n",
    "        valid_tokens += 1\n",
    "\n",
    "    return confidence_sum / valid_tokens if valid_tokens > 0 else 0.0\n",
    "\n",
    "\n",
    "def aggregate_paths_based_on_scores(paths: List[Tuple[str, float]]) -> Tuple[str, float]:\n",
    "    \"\"\"Aggregate multiple paths based on their confidence scores.\"\"\"\n",
    "    answer_scores = {}\n",
    "    for answer, delta in paths:\n",
    "        answer_scores[answer] = answer_scores.get(answer, 0) + delta\n",
    "    best_answer = max(answer_scores, key=answer_scores.get)\n",
    "    return best_answer, answer_scores[best_answer]\n",
    "\n",
    "\n",
    "def cot_decode(\n",
    "    model: PreTrainedModel,\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "    messages: List[Dict[str, str]],\n",
    "    k: int = 10,\n",
    "    num_beams: int = 1,\n",
    "    max_new_tokens: int = 512,\n",
    "    temperature: float = 1.0,\n",
    "    top_p: float = 1.0,\n",
    "    repetition_penalty: float = 1.0,\n",
    "    length_penalty: float = 1.0,\n",
    "    no_repeat_ngram_size: int = 0,\n",
    "    early_stopping: bool = False,\n",
    "    aggregate_paths: bool = False,\n",
    ") -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Implement CoT-decoding for a given chat input.\n",
    "\n",
    "    Args:\n",
    "        model: The Hugging Face transformer model.\n",
    "        tokenizer: The associated tokenizer.\n",
    "        messages: List of chat messages in the format [{\"role\": \"user\", \"content\": \"...\"}]\n",
    "        k: The number of alternative tokens to consider at the first step.\n",
    "        num_beams: Number of beams for beam search.\n",
    "        max_new_tokens: Maximum number of new tokens to generate.\n",
    "        temperature: Sampling temperature.\n",
    "        top_p: Nucleus sampling probability.\n",
    "        repetition_penalty: Repetition penalty factor.\n",
    "        length_penalty: Length penalty factor.\n",
    "        no_repeat_ngram_size: Size of n-grams to avoid repeating.\n",
    "        early_stopping: Whether to stop generation when all beams are finished.\n",
    "        aggregate_paths: Whether to aggregate multiple paths.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the best path (or aggregated result) and its confidence score.\n",
    "    \"\"\"\n",
    "    device = get_device()\n",
    "    model.to(device)\n",
    "\n",
    "    # Use the chat template to format the input\n",
    "    if tokenizer.chat_template:\n",
    "        input_text = tokenizer.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True)\n",
    "    else:\n",
    "        # Fallback for tokenizers without chat templates\n",
    "        input_text = \"\\n\".join(\n",
    "            [f\"{msg['role']}: {msg['content']}\" for msg in messages])\n",
    "        input_text += \"\\nassistant:\"\n",
    "\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    attention_mask = torch.ones_like(input_ids).to(device)\n",
    "\n",
    "    # Set pad_token_id if it's not set\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    # Get the top-k tokens for the first decoding step\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        first_token_logits = outputs.logits[0, -1, :]\n",
    "        top_k_logits, top_k_indices = torch.topk(first_token_logits, k)\n",
    "\n",
    "    paths = []\n",
    "    for idx in top_k_indices:\n",
    "        # Generate sequence starting with the selected token\n",
    "        start_ids = torch.cat(\n",
    "            [input_ids, idx.unsqueeze(0).unsqueeze(0)], dim=-1)\n",
    "        start_mask = torch.cat([attention_mask, torch.ones(\n",
    "            (1, 1), dtype=torch.long, device=device)], dim=-1)\n",
    "\n",
    "        output = model.generate(\n",
    "            start_ids,\n",
    "            attention_mask=start_mask,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_beams=num_beams,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "            length_penalty=length_penalty,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            early_stopping=early_stopping,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            output_scores=True,\n",
    "            return_dict_in_generate=True,\n",
    "        )\n",
    "\n",
    "        generated_sequence = output.sequences[0]\n",
    "        answer_ids = generated_sequence[len(input_ids[0]):]\n",
    "        print(f\"answer_ids: {answer_ids}\")\n",
    "        answer_text = tokenizer.decode(answer_ids, skip_special_tokens=True)\n",
    "        print(f\"answer_text: {answer_text}\")\n",
    "\n",
    "        # Calculate confidence score (Δ)\n",
    "        confidence = calculate_confidence(output.scores, answer_ids)\n",
    "        paths.append((answer_text, confidence))\n",
    "\n",
    "    if aggregate_paths:\n",
    "        return aggregate_paths_based_on_scores(paths)\n",
    "    else:\n",
    "        return max(paths, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb637b009852b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a215c49703c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d246dd8709f50be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, attn_implementation=\"eager\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"In a dance class of 20 students, 20% enrolled in contemporary dance, 25% of the remaining enrolled in jazz dance, and the rest enrolled in hip-hop dance. What percentage of the entire students enrolled in hip-hop dance?\"}\n",
    "]\n",
    "\n",
    "# # Generate the response using CoT decoding\n",
    "print(f\"Using device: {get_device()}\")\n",
    "result, confidence = cot_decode(\n",
    "    model, tokenizer, messages, aggregate_paths=True, max_new_tokens=512)\n",
    "print(f\"CoT Decoding:\\n {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f284afce1666435e",
   "metadata": {},
   "source": [
    "For setting up the data set (from Nilofar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f5be729063f7f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_gsm8k():\n",
    "    \"\"\"\n",
    "    Sets up the GSM8K dataset and provides basic analysis functionality.\n",
    "    Returns train and test datasets as pandas DataFrames.\n",
    "    \"\"\"\n",
    "    # Load the dataset using the Hugging Face datasets library\n",
    "    dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "\n",
    "    # Convert to pandas DataFrames for easier manipulation\n",
    "    train_df = pd.DataFrame(dataset['train'])\n",
    "    test_df = pd.DataFrame(dataset['test'])\n",
    "\n",
    "    # Create a directory for saving the data\n",
    "    data_dir = Path('C:\\\\Users\\\\roegn\\\\Documents\\\\Universität\\\\Master_Semester_III\\\\ML4NLP_Übung\\\\ML4NLP\\\\gsm8k_data')\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Save the datasets locally\n",
    "    train_df.to_csv(data_dir / 'train.csv', index=False)\n",
    "    test_df.to_csv(data_dir / 'test.csv', index=False)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "# def analyze_problem(problem):\n",
    "#     \"\"\"\n",
    "#     Analyzes a single GSM8K problem and its solution.\n",
    "#     \"\"\"\n",
    "#     lines = problem['answer'].split('\\n')\n",
    "#     solution_steps = [line for line in lines if line.startswith('<<')]\n",
    "#     final_answer = lines[-1] if lines else \"No answer found\"\n",
    "# \n",
    "#     return {\n",
    "#         'question': problem['question'],\n",
    "#         'solution_steps': solution_steps,\n",
    "#         'final_answer': final_answer\n",
    "#     }\n",
    "\n",
    " def analyze_problem(problem):\n",
    "     \"\"\"\n",
    "     Extracts the question and answer from a single GSM8K problem.\n",
    "     Problems without answers are not returned.\n",
    "     \"\"\"\n",
    "#     if re.findall(\"[0-9]/[0-9]\", problem['answer']):\n",
    "#         return\n",
    "     lines = problem['answer'].split('\\n')\n",
    "     #solution_steps = [line for line in lines if line.startswith('<<')]\n",
    "     \n",
    "     if lines:\n",
    "         final_answer = lines[-1].replace(\"#### \", '')\n",
    "         return {\n",
    "         'question': problem['question'],\n",
    "         'final_answer': final_answer\n",
    "     }\n",
    "     \n",
    "     #final_answer=\"No answer found\"\n",
    "#     return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c503ac514323b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a2e24470d213041",
   "metadata": {},
   "source": [
    "For a single instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23ecc5f7ff8b3fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 7473\n",
      "Test set size: 1319\n",
      "\n",
      "Example Problem Analysis:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m analysis \u001b[38;5;241m=\u001b[39m analyze_problem(first_problem)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExample Problem Analysis:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43manalysis\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#print(\"\\nSolution Steps:\")\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#for step in analysis['solution_steps']:\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#    print(step)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Answer:\u001b[39m\u001b[38;5;124m\"\u001b[39m, analysis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_answer\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Set up the dataset\n",
    "train_df, test_df = setup_gsm8k()\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n",
    "\n",
    "# Example: Analyze the first problem\n",
    "if len(train_df) > 0:\n",
    "    first_problem = train_df.iloc[0]\n",
    "    analysis = analyze_problem(first_problem)\n",
    "\n",
    "    print(\"\\nExample Problem Analysis:\")\n",
    "    print(\"Question:\", analysis['question'])\n",
    "\n",
    "    # print(\"\\nSolution Steps:\")\n",
    "    # for step in analysis['solution_steps']:\n",
    "    #    print(step)\n",
    "\n",
    "    print(\"\\nFinal Answer:\", analysis['final_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c92aa84e342a21e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:33:02.528776Z",
     "start_time": "2025-02-27T22:33:02.502027Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# from the example in the file on GitHub\u001b[39;00m\n\u001b[0;32m      2\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m----> 3\u001b[0m      {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43manalysis\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mA:\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m      4\u001b[0m  ]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Generate the response using CoT decoding\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_device()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# from the example in the file on GitHub\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"Q: {analysis['question']}\\nA:\"}\n",
    "]\n",
    "\n",
    "# Generate the response using CoT decoding\n",
    "print(f\"Using device: {get_device()}\")\n",
    "result, confidence = cot_decode(\n",
    "    model, tokenizer, messages, aggregate_paths=True, max_new_tokens=512)\n",
    "print(f\"CoT Decoding:\\n {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "244fd5ecda65166b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:38:13.596696Z",
     "start_time": "2025-02-27T22:38:13.589808Z"
    }
   },
   "outputs": [],
   "source": [
    "# identifying the actual answer to the question\n",
    "found = re.findall(r\"\\\\boxed\\{.+\\}|\\\\(.+\\\\)\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1ec73238100fad02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:51:45.470843Z",
     "start_time": "2025-02-27T22:51:45.461450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Answer. Correct Answer: 10, Answer given: 75\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "if found:\n",
    "\n",
    "    answer_span = re.sub(r\"\\\\|\\(|\\)|\\{|\\}|boxed\", \"\", found[-1])\n",
    "\n",
    "    if is_correct(final_answer, answer_span):\n",
    "        print(\"Correct Answer\", answer_span)\n",
    "    else:\n",
    "        print(\n",
    "            f\"Incorrect Answer. Correct Answer: {final_answer}, Answer given: {answer_span}\")\n",
    "else:\n",
    "    print(\"No answer was found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b1ea90243aa14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0800844ac9aef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e561ab0b4b59a1a5",
   "metadata": {},
   "source": [
    "For iterating through the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3b41884f3cf6a951",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:14:22.305329Z",
     "start_time": "2025-02-27T22:14:17.086323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 7473\n",
      "Test set size: 1319\n"
     ]
    }
   ],
   "source": [
    "# Set up the dataset\n",
    "train_df, test_df = setup_gsm8k()\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n",
    "\n",
    "\n",
    "# Prepare lists for questions and answers\n",
    "question_list = []\n",
    "answer_list = []\n",
    "\n",
    "for i in range(len(test_df)):\n",
    "    problem = test_df.iloc[i]\n",
    "\n",
    "    # eliminate tasks that include division as described in the original paper\n",
    "    if re.findall(\"[0-9]/[0-9]\", problem['answer']):\n",
    "        continue\n",
    "\n",
    "    question_list.append(problem['question'])\n",
    "    answer_list.append(problem['answer'].split('\\n')[-1].replace(\"#### \", ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0a04bbef07884",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-02-27T23:17:56.349895Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "correct: int = 0\n",
    "no_answer: int = 0\n",
    "# for analysis, if a sample comes without \"boxed\" we can retrieve it\n",
    "indexes_no_answer = []\n",
    "incorrect: int = 0\n",
    "indexes_incorrect = []  # for analysis\n",
    "\n",
    "for i in range(len(question_list)):\n",
    "\n",
    "    # Inference\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"Q: {question_list[i]}\\nA:\"}\n",
    "    ]\n",
    "\n",
    "    result, confidence = cot_decode(\n",
    "        model, tokenizer, messages, aggregate_paths=True, max_new_tokens=512)\n",
    "\n",
    "    # Finding the specific answer to the question in output\n",
    "    # Right now: work-around with \\boxed{}\n",
    "\n",
    "    found = re.findall(r\"\\\\boxed\\{.+\\}|\\\\(.+\\\\)\", result)\n",
    "\n",
    "    # comparing given answer to actual answer from the data set\n",
    "    if found:\n",
    "        # removing \\boxing ans brackets for comparison\n",
    "        answer_span = re.sub(r\"\\\\|\\(|\\)|\\{|\\}|boxed\", \"\", found[-1])\n",
    "        if is_correct(answer_list[i], answer_span):\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "            indexes_incorrect.append(f\"{i}: {answer_span}, {result}\")\n",
    "    else:\n",
    "        no_answer += 1\n",
    "        indexes_no_answer.append(result)\n",
    "\n",
    "    # to save time, limit number of operations\n",
    "    if i >= 200:\n",
    "        break\n",
    "\n",
    "# Calculating accuracy:\n",
    "print(f\"Accuracy: {correct/len(question_list) * 100} %\")\n",
    "\n",
    "# Cases were workaround did not work\n",
    "print(f\"No answers found: {no_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ba93c4294699ab98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T23:07:55.576501Z",
     "start_time": "2025-02-27T23:07:55.568361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To determine how far John is from home at the end of 4 hours, we can break down the problem into several steps:\\n\\n1. Calculate the distance John travels during the first 2 hours:\\n\\\\[ \\\\text{Distance} = \\\\text{Speed} \\\\times \\\\text{Time} = 60 \\\\text{ mph} \\\\times 2 \\\\text{ hours} = 120 \\\\text{ miles} \\\\]\\n\\n2. Calculate the remaining distance after the first 2 hours:\\n\\\\[ \\\\text{Distance after first 2 hours} = \\\\text{Total distance} - \\\\text{Distance during first 2 hours} = 280 \\\\text{ miles} - 120 \\\\text{ miles} = 160 \\\\text{ miles} \\\\]\\n\\n3. Calculate the distance John travels during the next half-hour:\\n\\\\[ \\\\text{Distance} = \\\\text{Speed} \\\\times \\\\text{Time} = 30 \\\\text{ mph} \\\\times 0.5 \\\\text{ hours} = 15 \\\\text{ miles} \\\\]\\n\\n4. Calculate the remaining distance after driving 0.5 hours:\\n\\\\[ \\\\text{Distance after next half-hour} = \\\\text{Remaining distance} - \\\\text{Distance traveled} = 160 \\\\text{ miles} - 15 \\\\text{ miles} = 145 \\\\text{ miles} \\\\]\\n\\n5. Sum the remaining distances to get the total distance John was 2 hours late:\\n\\\\[ \\\\text{Total remaining distance} = 145 \\\\text{ miles} + 0.5 \\\\text{ miles} = 145.5 \\\\text{ miles} \\\\]\\n\\n6. Calculate the total distance traveled:\\n\\\\[ \\\\text{Total distance} = \\\\text{Distance by car} + \\\\text{Distance in standstill} + \\\\text{Distance by bus} = 280 \\\\text{ miles} + 0 \\\\text{ miles} + 160 \\\\text{ miles} = 440 \\\\text{ miles} \\\\]\\n\\n7. Calculate the distance left to reach home:\\n\\\\[ \\\\text{Distance remaining} = \\\\text{Total distance} - \\\\text{Distance} = 440 \\\\text{ miles} - 280 \\\\text{ miles} = 160 \\\\text{ miles} \\\\]\\n\\n8. Calculate how far John is from his starting point:\\n\\\\[ \\\\text{'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b2c2bf8a16c08e09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T23:08:38.445324Z",
     "start_time": "2025-02-27T23:08:38.434632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Q: John drives for 3 hours at a speed of 60 mph and then turns around because he realizes he forgot something very important at home.  He tries to get home in 4 hours but spends the first 2 hours in standstill traffic.  He spends the next half-hour driving at a speed of 30mph, before being able to drive the remaining time of the 4 hours going at 80 mph.  How far is he from home at the end of those 4 hours?\\nA:'}]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "801a04c9c54cec35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T23:11:48.161452Z",
     "start_time": "2025-02-27T23:11:48.155065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_no_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "703bbe28c1b9a843",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T23:15:16.135174Z",
     "start_time": "2025-02-27T23:15:16.127903Z"
    }
   },
   "outputs": [],
   "source": [
    "indexes_incorrect.append(f\"{i}: {answer_span}, {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "987434825aff0244",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T23:15:17.867958Z",
     "start_time": "2025-02-27T23:15:17.856686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 3,\n",
       " 5,\n",
       " '5: result',\n",
       " '5: [ ',\n",
       " '5: [ , To determine how far John is from home at the end of 4 hours, we can break down the problem into several steps:\\n\\n1. Calculate the distance John travels during the first 2 hours:\\n\\\\[ \\\\text{Distance} = \\\\text{Speed} \\\\times \\\\text{Time} = 60 \\\\text{ mph} \\\\times 2 \\\\text{ hours} = 120 \\\\text{ miles} \\\\]\\n\\n2. Calculate the remaining distance after the first 2 hours:\\n\\\\[ \\\\text{Distance after first 2 hours} = \\\\text{Total distance} - \\\\text{Distance during first 2 hours} = 280 \\\\text{ miles} - 120 \\\\text{ miles} = 160 \\\\text{ miles} \\\\]\\n\\n3. Calculate the distance John travels during the next half-hour:\\n\\\\[ \\\\text{Distance} = \\\\text{Speed} \\\\times \\\\text{Time} = 30 \\\\text{ mph} \\\\times 0.5 \\\\text{ hours} = 15 \\\\text{ miles} \\\\]\\n\\n4. Calculate the remaining distance after driving 0.5 hours:\\n\\\\[ \\\\text{Distance after next half-hour} = \\\\text{Remaining distance} - \\\\text{Distance traveled} = 160 \\\\text{ miles} - 15 \\\\text{ miles} = 145 \\\\text{ miles} \\\\]\\n\\n5. Sum the remaining distances to get the total distance John was 2 hours late:\\n\\\\[ \\\\text{Total remaining distance} = 145 \\\\text{ miles} + 0.5 \\\\text{ miles} = 145.5 \\\\text{ miles} \\\\]\\n\\n6. Calculate the total distance traveled:\\n\\\\[ \\\\text{Total distance} = \\\\text{Distance by car} + \\\\text{Distance in standstill} + \\\\text{Distance by bus} = 280 \\\\text{ miles} + 0 \\\\text{ miles} + 160 \\\\text{ miles} = 440 \\\\text{ miles} \\\\]\\n\\n7. Calculate the distance left to reach home:\\n\\\\[ \\\\text{Distance remaining} = \\\\text{Total distance} - \\\\text{Distance} = 440 \\\\text{ miles} - 280 \\\\text{ miles} = 160 \\\\text{ miles} \\\\]\\n\\n8. Calculate how far John is from his starting point:\\n\\\\[ \\\\text{']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c66b29aaec2d84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
