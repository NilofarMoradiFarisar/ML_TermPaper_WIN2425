{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:11:17.920930Z",
     "start_time": "2025-02-28T10:11:13.128500Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Python311\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd27df768845d15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:23:22.036334Z",
     "start_time": "2025-02-28T10:23:22.019076Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def calculate_confidence(logits: List[torch.Tensor], answer_ids: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the confidence score (Δ) as specified in the paper.\n",
    "\n",
    "    Args:\n",
    "        logits: List of logits for each decoding step\n",
    "        answer_ids: Tensor of token ids for the answer\n",
    "\n",
    "    Returns:\n",
    "        Confidence score (Δ)\n",
    "    \"\"\"\n",
    "    confidence_sum = 0.0\n",
    "    valid_tokens = 0\n",
    "    for t, token_id in enumerate(answer_ids):\n",
    "        if t >= len(logits):\n",
    "            break\n",
    "        token_logits = logits[t]\n",
    "        probs = torch.softmax(token_logits, dim=-1)\n",
    "        if probs.size(-1) > 1:\n",
    "            top_2_probs, _ = torch.topk(probs, min(2, probs.size(-1)))\n",
    "            if top_2_probs.size(-1) > 1:\n",
    "                confidence_sum += (top_2_probs[-1]\n",
    "                                   [0] - top_2_probs[-1][1]).item()\n",
    "            else:\n",
    "                confidence_sum += 1.0  # Max confidence if there's only one token\n",
    "        else:\n",
    "            confidence_sum += 1.0  # Max confidence if there's only one token\n",
    "        valid_tokens += 1\n",
    "\n",
    "    return confidence_sum / valid_tokens if valid_tokens > 0 else 0.0\n",
    "\n",
    "\n",
    "def aggregate_paths_based_on_scores(paths: List[Tuple[str, float]]) -> Tuple[str, float]:\n",
    "    \"\"\"Aggregate multiple paths based on their confidence scores.\"\"\"\n",
    "    answer_scores = {}\n",
    "    for answer, delta in paths:\n",
    "        answer_scores[answer] = answer_scores.get(answer, 0) + delta\n",
    "    best_answer = max(answer_scores, key=answer_scores.get)\n",
    "    return best_answer, answer_scores[best_answer]\n",
    "\n",
    "\n",
    "def cot_decode(\n",
    "    model: PreTrainedModel,\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "    messages: List[Dict[str, str]],\n",
    "    k: int = 10,\n",
    "    num_beams: int = 1,\n",
    "    max_new_tokens: int = 512,\n",
    "    temperature: float = 1.0,\n",
    "    top_p: float = 1.0,\n",
    "    repetition_penalty: float = 1.0,\n",
    "    length_penalty: float = 1.0,\n",
    "    no_repeat_ngram_size: int = 0,\n",
    "    early_stopping: bool = False,\n",
    "    aggregate_paths: bool = False,\n",
    ") -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Implement CoT-decoding for a given chat input.\n",
    "\n",
    "    Args:\n",
    "        model: The Hugging Face transformer model.\n",
    "        tokenizer: The associated tokenizer.\n",
    "        messages: List of chat messages in the format [{\"role\": \"user\", \"content\": \"...\"}]\n",
    "        k: The number of alternative tokens to consider at the first step.\n",
    "        num_beams: Number of beams for beam search.\n",
    "        max_new_tokens: Maximum number of new tokens to generate.\n",
    "        temperature: Sampling temperature.\n",
    "        top_p: Nucleus sampling probability.\n",
    "        repetition_penalty: Repetition penalty factor.\n",
    "        length_penalty: Length penalty factor.\n",
    "        no_repeat_ngram_size: Size of n-grams to avoid repeating.\n",
    "        early_stopping: Whether to stop generation when all beams are finished.\n",
    "        aggregate_paths: Whether to aggregate multiple paths.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the best path (or aggregated result) and its confidence score.\n",
    "    \"\"\"\n",
    "    device = get_device()\n",
    "    model.to(device)\n",
    "\n",
    "    # Use the chat template to format the input\n",
    "    if tokenizer.chat_template:\n",
    "        input_text = tokenizer.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True)\n",
    "    else:\n",
    "        # Fallback for tokenizers without chat templates\n",
    "        input_text = \"\\n\".join(\n",
    "            [f\"{msg['role']}: {msg['content']}\" for msg in messages])\n",
    "        input_text += \"\\nassistant:\"\n",
    "\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    attention_mask = torch.ones_like(input_ids).to(device)\n",
    "\n",
    "    # Set pad_token_id if it's not set\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    # Get the top-k tokens for the first decoding step\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        first_token_logits = outputs.logits[0, -1, :]\n",
    "        top_k_logits, top_k_indices = torch.topk(first_token_logits, k)\n",
    "\n",
    "    paths = []\n",
    "    for idx in top_k_indices:\n",
    "        # Generate sequence starting with the selected token\n",
    "        start_ids = torch.cat(\n",
    "            [input_ids, idx.unsqueeze(0).unsqueeze(0)], dim=-1)\n",
    "        start_mask = torch.cat([attention_mask, torch.ones(\n",
    "            (1, 1), dtype=torch.long, device=device)], dim=-1)\n",
    "\n",
    "        output = model.generate(\n",
    "            start_ids,\n",
    "            attention_mask=start_mask,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_beams=num_beams,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "            length_penalty=length_penalty,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            early_stopping=early_stopping,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            output_scores=True,\n",
    "            return_dict_in_generate=True,\n",
    "        )\n",
    "\n",
    "        generated_sequence = output.sequences[0]\n",
    "        answer_ids = generated_sequence[len(input_ids[0]):]\n",
    "        # print(f\"answer_ids: {answer_ids}\")\n",
    "        answer_text = tokenizer.decode(answer_ids, skip_special_tokens=True)\n",
    "        # print(f\"answer_text: {answer_text}\")\n",
    "\n",
    "        # Calculate confidence score (Δ)\n",
    "        confidence = calculate_confidence(output.scores, answer_ids)\n",
    "        paths.append((answer_text, confidence))\n",
    "\n",
    "    if aggregate_paths:\n",
    "        return aggregate_paths_based_on_scores(paths)\n",
    "    else:\n",
    "        return max(paths, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6bb0b1eca2222203",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T11:45:56.538515Z",
     "start_time": "2025-02-28T11:45:56.524233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "# name list\n",
    "# provided by authors\n",
    "\n",
    "names_string = \"\"\"Sasha Calle\n",
    "Annie Murphy\n",
    "Golshifteh Farahani\n",
    "Kate Mara\n",
    "Josh Hartnett\n",
    "Jennifer Lawrence\n",
    "Aaron Taylor-Johnson\n",
    "Rebecca Ferguson\n",
    "Monica Barbaro\n",
    "Chris Hemsworth\n",
    "Wes Anderson\n",
    "Daniel Portman\n",
    "Lily-Rose Depp\n",
    "Myha'la Herrold\n",
    "Zendaya\n",
    "Ezra Miller\n",
    "Olga Kurylenko\n",
    "Zazie Beetz\n",
    "Arnold Schwarzenegger\n",
    "Emilia Clarke\n",
    "Jess Bush\n",
    "Clara Rugaard\n",
    "Molly Gordon\n",
    "Isabel May\n",
    "Hailee Steinfeld\n",
    "Hannah Waddingham\n",
    "Rory Culkin\n",
    "Cobie Smulders\n",
    "Harrison Ford\n",
    "Tom Cruise\n",
    "Carol Kane\n",
    "Alexandra Daddario\n",
    "Gal Gadot\n",
    "Tom Holland\n",
    "Hayley Atwell\n",
    "Salma Hayek\n",
    "Ana de Armas\n",
    "Will Poulter\n",
    "Anson Mount\n",
    "Paapa Essiedu\n",
    "Sam Hargrave\n",
    "Margot Robbie\n",
    "Nicolas Cage\n",
    "Henry Cavill\n",
    "Juno Temple\n",
    "Cailee Spaeny\n",
    "Treat Williams\n",
    "Alexander Skarsgård\n",
    "Rebecca Romijn\n",
    "Monica Dolan\n",
    "Anya Taylor-Joy\n",
    "Sophia Lillis\n",
    "Emmanuelle Vaugier\n",
    "Aaron Paul\n",
    "Elliot Page\n",
    "Robin Tunney\n",
    "Mike Faist\n",
    "Tinatin Dalakishvili\n",
    "Sarah Snook\n",
    "Jenna Ortega\n",
    "Zoe Saldana\n",
    "Anjana Vasan\n",
    "Ben Mendelsohn\n",
    "Jeremy Allen White\n",
    "Ayo Edebiri\n",
    "Keanu Reeves\n",
    "Pom Klementieff\n",
    "Scarlett Johansson\n",
    "Tornike Gogrichiani\n",
    "James Cameron\n",
    "Pedro Pascal\n",
    "Kaley Cuoco\n",
    "Samuel L. Jackson\n",
    "Terri Ivens\n",
    "Florence Pugh\n",
    "Shea Whigham\n",
    "Kingsley Ben-Adir\n",
    "Michael Keaton\n",
    "Julian Sands\n",
    "Christopher Nolan\n",
    "Tom Hanks\n",
    "Clint Eastwood\n",
    "Gabriel Macht\n",
    "Fabiana Udenio\n",
    "Tom Bateman\n",
    "Jack Champion\n",
    "Jake Gyllenhaal\n",
    "Leonardo DiCaprio\n",
    "Jason Schwartzman\n",
    "Grace Caroline Currey\n",
    "Sydney Sweeney\n",
    "Emily Rudd\n",
    "Samuel Blenkin\n",
    "James Marsden\n",
    "Jesse Plemons\n",
    "Alan Ritchson\n",
    "Cillian Murphy\n",
    "Meghan Markle\n",
    "Tyler Hoechlin\n",
    "Angelina Jolie\n",
    "\"\"\"\n",
    "# Christina Chong: excluded due to different information regarding date and year of birth, nothing mentioned on Wikipedia\n",
    "# One double\n",
    "# Two added names (Tyler Hoechlin, Angelina Jolie) to get to 100\n",
    "\n",
    "name_list = names_string.split(\"\\n\")\n",
    "print(len(name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f0438cdd8b0f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T11:46:42.169374Z",
     "start_time": "2025-02-28T11:46:42.155589Z"
    }
   },
   "outputs": [],
   "source": [
    "# provided by the authors\n",
    "# taken from predictions by another model\n",
    "# manually checked for correctness by us (Wikipedia)\n",
    "# two added entries due to one double in the original list and one unclear case; now len = 100\n",
    "\n",
    "year_map = {'Sasha Calle': '1995', 'Annie Murphy': '1986', 'Golshifteh Farahani': '1983', 'Kate Mara': '1983', 'Josh Hartnett': '1978', 'Jennifer Lawrence': '1990', 'Aaron Taylor-Johnson': '1990', 'Rebecca Ferguson': '1983', 'Monica Barbaro': '1990', 'Chris Hemsworth': '1983',\n",
    "\n",
    "            'Wes Anderson': '1969', 'Daniel Portman': '1992', 'Lily-Rose Depp': '1999', \"Myha'la Herrold\": '1996', 'Zendaya': '1996', 'Ezra Miller': '1992', 'Olga Kurylenko': '1979', 'Zazie Beetz': '1991', 'Arnold Schwarzenegger': '1947', 'Emilia Clarke': '1986',\n",
    "\n",
    "            'Jess Bush': '1992', 'Clara Rugaard': '1997', 'Molly Gordon': '1994', 'Isabel May': '2000', 'Hailee Steinfeld': '1996', 'Hannah Waddingham': '1974', 'Christina Chong': '1983', 'Rory Culkin': '1989', 'Cobie Smulders': '1982', 'Harrison Ford': '1942',\n",
    "\n",
    "            'Tom Cruise': '1962', 'Carol Kane': '1952', 'Alexandra Daddario': '1986', 'Gal Gadot': '1985', 'Tom Holland': '1996', 'Hayley Atwell': '1982', 'Salma Hayek': '1966', 'Ana de Armas': '1988', 'Will Poulter': '1993', 'Anson Mount': '1973',\n",
    "\n",
    "            'Paapa Essiedu': '1990', 'Sam Hargrave': '1982', 'Margot Robbie': '1990', 'Nicolas Cage': '1964', 'Henry Cavill': '1983', 'Juno Temple': '1989', 'Cailee Spaeny': '1998', 'Treat Williams': '1951',\n",
    "\n",
    "            'Alexander Skarsgård': '1976', 'Rebecca Romijn': '1972', 'Monica Dolan': '1969', 'Anya Taylor-Joy': '1996', 'Sophia Lillis': '2002', 'Emmanuelle Vaugier': '1976', 'Aaron Paul': '1979', 'Elliot Page': '1987', 'Robin Tunney': '1972', 'Mike Faist': '1992',\n",
    "\n",
    "            'Tinatin Dalakishvili': '1991', 'Sarah Snook': '1987', 'Jenna Ortega': '2002', 'Zoe Saldana': '1978', 'Anjana Vasan': '1987', 'Ben Mendelsohn': '1969', 'Jeremy Allen White': '1991', 'Ayo Edebiri': '1995', 'Keanu Reeves': '1964', 'Pom Klementieff': '1986',\n",
    "\n",
    "            'Scarlett Johansson': '1984', 'Tornike Gogrichiani': '1986', 'James Cameron': '1954', 'Pedro Pascal': '1975', 'Kaley Cuoco': '1985', 'Samuel L. Jackson': '1948', 'Terri Ivens': '1967', 'Florence Pugh': '1996', 'Shea Whigham': '1969',\n",
    "\n",
    "            'Kingsley Ben-Adir': '1986', 'Michael Keaton': '1951', 'Julian Sands': '1958', 'Christopher Nolan': '1970', 'Tom Hanks': '1956', 'Clint Eastwood': '1930', 'Gabriel Macht': '1972', 'Fabiana Udenio': '1964', 'Tom Bateman': '1989', 'Jack Champion': '2004',\n",
    "\n",
    "            'Jake Gyllenhaal': '1980', 'Leonardo DiCaprio': '1974', 'Jason Schwartzman': '1980', 'Grace Caroline Currey': '1996', 'Sydney Sweeney': '1997', 'Emily Rudd': '1993', 'Samuel Blenkin': '1996', 'James Marsden': '1973', 'Jesse Plemons': '1988', 'Alan Ritchson': '1982',\n",
    "\n",
    "            'Cillian Murphy': '1976', 'Meghan Markle': '1981', 'Tyler Hoechlin': '1987', 'Angelina Jolie': '1975'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6a9be08768ce19a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T11:46:44.178167Z",
     "start_time": "2025-02-28T11:46:44.157689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(year_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320031b34014a9ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T11:46:45.493722Z",
     "start_time": "2025-02-28T11:46:45.482627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in name_list:\n",
    "\n",
    "    # Query and target\n",
    "    text = \"Was \" + name + \" born in an even or odd year?\"\n",
    "    if name not in year_map:\n",
    "        print(name)\n",
    "    else:\n",
    "        print(\"in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31279a0a38db8bc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:22:44.721771Z",
     "start_time": "2025-02-28T10:22:43.049050Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, attn_implementation=\"eager\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2e79b38459a2815",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:12:43.721985Z",
     "start_time": "2025-02-28T10:12:43.717044Z"
    }
   },
   "outputs": [],
   "source": [
    "# from the authors, modified\n",
    "name = \"Nicolas Cage\"\n",
    "text = \"Q: Was \" + name + \" born in an even or odd year?\\nA:\"\n",
    "if name not in year_map:\n",
    "    print(\"Name not in data set.\")\n",
    "year = int(year_map[name])\n",
    "if year % 2 == 0:\n",
    "    target = 'even'\n",
    "else:\n",
    "    target = 'odd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475594453302b3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:24:13.159444Z",
     "start_time": "2025-02-28T10:23:27.860043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CoT Decoding:\n",
      " Nicholas Cage was born in January 1974 in Houston, Texas, United States. Texas is an odd-numbered state, so Nicolas Cage would have been born in an odd-numbered year.\n"
     ]
    }
   ],
   "source": [
    "# from the example in the file on GitHub, modified\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"Q: {text}\\nA:\"}\n",
    "]\n",
    "\n",
    "# Generate the response using CoT decoding\n",
    "print(f\"Using device: {get_device()}\")\n",
    "result, confidence = cot_decode(\n",
    "    model, tokenizer, messages, aggregate_paths=True, max_new_tokens=200)\n",
    "print(f\"CoT Decoding:\\n {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cd71bc4bf73c6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:25:08.853835Z",
     "start_time": "2025-02-28T10:25:08.847223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Answer. Correct Answer: even, Answer given: odd\n"
     ]
    }
   ],
   "source": [
    "# identifying the actual answer to the question\n",
    "found = re.findall(r\"\\Weven\\W|\\Wodd\\W\", result, flags=re.IGNORECASE)\n",
    "\n",
    "# evaluation\n",
    "if found:\n",
    "    answer = re.sub(r\"\\W\", \"\", found[-1])\n",
    "    if target == answer.lower():\n",
    "        print(\"Correct Answer: \", target)\n",
    "    else:\n",
    "        print(\n",
    "            f\"Incorrect Answer. Correct Answer: {target}, Answer given: {answer}\")\n",
    "else:\n",
    "    print(\"No answer was found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15507d80b869fa6f",
   "metadata": {},
   "source": [
    "Iterating through the name list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f338b1a370e30c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:37:59.196541Z",
     "start_time": "2025-02-28T10:37:59.189306Z"
    }
   },
   "outputs": [],
   "source": [
    "name_list = [\"Sasha Calle\", \"Annie Murphy\",\n",
    "             \"Golshifteh Farahani\", \"Kate Mara\", \"Josh Hartnett\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55cd07ca219e4da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:50:54.246161Z",
     "start_time": "2025-02-28T10:45:43.383677Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'question_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 42\u001b[0m\n\u001b[0;32m     38\u001b[0m         indexes_no_answer\u001b[38;5;241m.\u001b[39mappend([name, result, target])\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Calculating accuracy:\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[43mquestion_list\u001b[49m)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m %\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Cases were workaround did not work\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo answers found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mno_answer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'question_list' is not defined"
     ]
    }
   ],
   "source": [
    "correct: int = 0\n",
    "no_answer: int = 0\n",
    "# for analysis, if a sample comes without \"boxed\" we can retrieve it\n",
    "indexes_no_answer = []\n",
    "incorrect: int = 0\n",
    "indexes_incorrect = []  # for analysis\n",
    "\n",
    "for name in name_list:\n",
    "\n",
    "    # Query and target\n",
    "    text = \"Was \" + name + \" born in an even or odd year?\"\n",
    "    if name not in year_map:\n",
    "        continue\n",
    "    year = int(year_map[name])\n",
    "    if year % 2 == 0:\n",
    "        target = 'even'\n",
    "    else:\n",
    "        target = 'odd'\n",
    "\n",
    "    # inference\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"Q: {text}\\nA:\"}\n",
    "    ]\n",
    "    result, confidence = cot_decode(\n",
    "        model, tokenizer, messages, aggregate_paths=True, max_new_tokens=200)\n",
    "\n",
    "    # identifying answer\n",
    "    found = re.findall(r\"\\Weven\\W|\\Wodd\\W\", result, flags=re.IGNORECASE)\n",
    "\n",
    "    # evaluation\n",
    "    if found:\n",
    "        answer = re.sub(r\"\\W\", \"\", found[-1])\n",
    "        if target == answer.lower():\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "            indexes_incorrect.append([name, result, target])\n",
    "    else:\n",
    "        no_answer += 1\n",
    "        indexes_no_answer.append([name, result, target])\n",
    "\n",
    "\n",
    "# Calculating accuracy:\n",
    "print(f\"Accuracy: {correct/len(name_list) * 100} %\")\n",
    "\n",
    "# Cases were workaround did not work\n",
    "print(f\"No answers found: {no_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f64f62bc355fae9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:52:01.067920Z",
     "start_time": "2025-02-28T10:52:01.056243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/len(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b7aad8f5e52c742",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:52:12.129841Z",
     "start_time": "2025-02-28T10:52:12.114698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Sasha Calle',\n",
       "  'To determine the year in which Sasha Calle was born, we need to consider the year in which the current day is located on the calendar.\\n\\nAssuming the current date is the 20th of April 2023 (a common date for a child born in the 21st century):\\n\\n1. March:\\n   - In which month is April 2023 located in the calendar?\\n\\n2. April:\\n   - April is the 4th month of the year.\\n\\n3. May:\\n   - The month after April is May.\\n\\n4. June:\\n   - The month after May is June.\\n\\n5. July:\\n   - The month after July might be August.\\n\\n6. August:\\n   - The month after August is September.\\n\\n7. September:\\n   - The month after September is October.\\n\\n8. October:\\n   - The month after October is November.\\n\\n9. November:\\n   - The month after November is December.\\n\\n10. December:\\n    - The',\n",
       "  'odd']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_no_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16948df4c00c518",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:53:13.486305Z",
     "start_time": "2025-02-28T10:53:13.465136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Josh Hartnett',\n",
       "  'According to the information available to me, Josh Hartnett was born in 1981, which is an odd year.',\n",
       "  'even']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b57fada5ccac3a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:52:10.377254Z",
     "start_time": "2025-02-28T10:52:10.367278Z"
    }
   },
   "outputs": [],
   "source": [
    "help_string = \"'The correct answer is: Sasha Calle was born in the year 1990. The date of her birth, July 30, 1990, was a leap year, and the year 1990 was also an even number. Odd numbers are numbers ending in 1, 3, 5, 7, or 9, while even numbers are numbers ending in 0, 2, 4, 6, or 8.\"\n",
    "help_result = 'odd'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8672b79b2c69d",
   "metadata": {},
   "source": [
    "Greedy Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a27de4b7255af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8d5e9b77ea43a3",
   "metadata": {},
   "source": [
    "Single answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2df290a2cd7af271",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:54:17.048599Z",
     "start_time": "2025-02-28T10:54:17.037153Z"
    }
   },
   "outputs": [],
   "source": [
    "# from the authors, modified\n",
    "name = \"Nicolas Cage\"\n",
    "text = \"Was \" + name + \" born in an even or odd year?\"\n",
    "if name not in year_map:\n",
    "    print(\"Name not in data set.\")\n",
    "year = int(year_map[name])\n",
    "if year % 2 == 0:\n",
    "    target = 'even'\n",
    "else:\n",
    "    target = 'odd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d5c43580d99fe11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:54:54.493214Z",
     "start_time": "2025-02-28T10:54:53.203330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Was Nicolas Cage born in an even or odd year?\n",
      "A: Even\n",
      "What is the answer? (Available options:\n",
      " -even\n",
      " -odd)\n"
     ]
    }
   ],
   "source": [
    "# encode context the generation is conditioned on\n",
    "model_inputs = tokenizer(f\"Q: {text}\\nA:\", return_tensors='pt').to(\"cuda\")\n",
    "\n",
    "# generate 40 new tokens\n",
    "greedy_output = model.generate(\n",
    "    **model_inputs,\n",
    "    num_beams=1,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d0a4428f548e10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:55:35.866950Z",
     "start_time": "2025-02-28T10:55:35.845901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Answer. Correct Answer: even, Answer given: odd\n"
     ]
    }
   ],
   "source": [
    "# identifying the actual answer to the question\n",
    "found = re.findall(r\"\\Weven\\W|\\Wodd\\W\", result, flags=re.IGNORECASE)\n",
    "\n",
    "# evaluation\n",
    "if found:\n",
    "    # for greedy decoding, choose the first occurence of even / odd\n",
    "    answer = re.sub(r\"\\W\", \"\", found[0])\n",
    "    if target == answer.lower():\n",
    "        print(\"Correct Answer: \", target)\n",
    "    else:\n",
    "        print(\n",
    "            f\"Incorrect Answer. Correct Answer: {target}, Answer given: {answer}\")\n",
    "else:\n",
    "    print(\"No answer was found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12754953565b48c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:56:45.888428Z",
     "start_time": "2025-02-28T10:56:45.881526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sasha Calle',\n",
       " 'Annie Murphy',\n",
       " 'Golshifteh Farahani',\n",
       " 'Kate Mara',\n",
       " 'Josh Hartnett']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f244babae116d99d",
   "metadata": {},
   "source": [
    "Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e459ab550dcf0890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:57:26.375545Z",
     "start_time": "2025-02-28T10:57:15.469272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.0 %\n",
      "No answers found: 0\n"
     ]
    }
   ],
   "source": [
    "correct: int = 0\n",
    "no_answer: int = 0\n",
    "# for analysis, if a sample comes without \"boxed\" we can retrieve it\n",
    "indexes_no_answer = []\n",
    "incorrect: int = 0\n",
    "indexes_incorrect = []  # for analysis\n",
    "\n",
    "for name in name_list:\n",
    "\n",
    "    # Query and target\n",
    "    text = \"Was \" + name + \" born in an even or odd year?\"\n",
    "    if name not in year_map:\n",
    "        continue\n",
    "    year = int(year_map[name])\n",
    "    if year % 2 == 0:\n",
    "        target = 'even'\n",
    "    else:\n",
    "        target = 'odd'\n",
    "\n",
    "    # inference\n",
    "    model_inputs = tokenizer(f\"Q: {text}\\nA:\", return_tensors='pt').to(\"cuda\")\n",
    "\n",
    "    greedy_output = model.generate(\n",
    "        **model_inputs,\n",
    "        num_beams=1,\n",
    "        do_sample=False,\n",
    "        max_new_tokens=40\n",
    "    )\n",
    "\n",
    "    result = tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n",
    "\n",
    "    # identifying answer\n",
    "    found = re.findall(r\"\\Weven\\W|\\Wodd\\W\", result, flags=re.IGNORECASE)\n",
    "\n",
    "    # evaluation\n",
    "    if found:\n",
    "        answer = re.sub(r\"\\W\", \"\", found[-1])\n",
    "        if target == answer.lower():\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "            indexes_incorrect.append([name, result, target])\n",
    "    else:\n",
    "        no_answer += 1\n",
    "        indexes_no_answer.append([name, result, target])\n",
    "\n",
    "\n",
    "# Calculating accuracy:\n",
    "print(f\"Accuracy: {correct/len(name_list) * 100} %\")\n",
    "\n",
    "# Cases were workaround did not work\n",
    "print(f\"No answers found: {no_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30919b5a166bc24d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:57:55.046778Z",
     "start_time": "2025-02-28T10:57:55.033684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Kate Mara',\n",
       "  'Q: Was Kate Mara born in an even or odd year?\\nA: Even\\nExplanation for the above answer:\\nKate Mara was born on February 1, 1964. February is the second month of the year and it falls between January and March. The',\n",
       "  'odd']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_incorrect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch GPU (Python 3.11)",
   "language": "python",
   "name": "pytorch-gpu-python-3-11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
