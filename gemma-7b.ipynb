{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7473 problems from training set\n",
      "\n",
      "Testing with first problem:\n",
      "Question: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "\n",
      "Solution:\n",
      "**Step 1**: Find the number of clips Natalia sold in April. \n",
      "\n",
      "Natalia sold clips to 48 friends in April, so the number of clips she sold in April was 48.\n",
      "\n",
      "**Step 2**: Find the number of clips Natalia sold in May.\n",
      "\n",
      "Half as many clips were sold in May as she sold in April, so Natalia sold 48/2 = 24 clips in May.\n",
      "\n",
      "**Step 3**: Find the total number of clips Natalia sold in April and May.\n",
      "\n",
      "Natalia sold 48 in April and 24 in May, so she sold a total of 48 + 24 = 72 clips altogether in April and May.\n"
     ]
    }
   ],
   "source": [
    "class OllamaGSM8K:\n",
    "    def __init__(self, model=\"gemma:2b\"):\n",
    "        self.model = model\n",
    "        self.api_url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "    def generate_prompt(self, question):\n",
    "        \"\"\"Create a structured prompt for the math problem.\"\"\"\n",
    "        return f\"\"\"Solve this math problem step by step:\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Let's solve this step by step:\"\"\"\n",
    "\n",
    "    def call_ollama(self, prompt):\n",
    "        \"\"\"Make API call to Ollama.\"\"\"\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.api_url,\n",
    "                json={\n",
    "                    \"model\": self.model,\n",
    "                    \"prompt\": prompt,\n",
    "                    \"stream\": False\n",
    "                }\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            return response.json()['response']\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error calling Ollama API: {e}\")\n",
    "            return None\n",
    "\n",
    "    def solve_problem(self, question):\n",
    "        \"\"\"Solve a single GSM8K problem.\"\"\"\n",
    "        prompt = self.generate_prompt(question)\n",
    "        response = self.call_ollama(prompt)\n",
    "        return {\n",
    "            'question': question,\n",
    "            'solution': response\n",
    "        }\n",
    "\n",
    "    def batch_solve(self, questions, batch_size=5):\n",
    "        \"\"\"Solve multiple problems with delay between batches.\"\"\"\n",
    "        solutions = []\n",
    "        for i in range(0, len(questions), batch_size):\n",
    "            batch = questions[i:i + batch_size]\n",
    "            print(f\"Processing batch {i//batch_size + 1}...\")\n",
    "\n",
    "            for question in batch:\n",
    "                solution = self.solve_problem(question)\n",
    "                solutions.append(solution)\n",
    "                time.sleep(1)  # Delay between problems\n",
    "\n",
    "            if i + batch_size < len(questions):\n",
    "                print(\"Waiting between batches...\")\n",
    "                time.sleep(5)  # Delay between batches\n",
    "\n",
    "        return solutions\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load your local GSM8K dataset\n",
    "    try:\n",
    "        train_df = pd.read_csv(\n",
    "            'C:/Users/Nilofar/Desktop/ML_TermPaper_WIN2425/datasets/gsm8k_data/train.csv')\n",
    "        print(f\"Loaded {len(train_df)} problems from training set\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Please ensure your GSM8K dataset is in 'gsm8k_data/train.csv'\")\n",
    "        return\n",
    "\n",
    "    # Initialize the solver\n",
    "    solver = OllamaGSM8K()\n",
    "\n",
    "    # Test with a single problem first\n",
    "    test_question = train_df['question'].iloc[0]\n",
    "    print(\"\\nTesting with first problem:\")\n",
    "    print(\"Question:\", test_question)\n",
    "\n",
    "    result = solver.solve_problem(test_question)\n",
    "    print(\"\\nSolution:\")\n",
    "    print(result['solution'])\n",
    "\n",
    "    # Example of batch processing (uncomment to use)\n",
    "    \"\"\"\n",
    "    # Process first 10 problems\n",
    "    sample_questions = train_df['question'].head(10).tolist()\n",
    "    solutions = solver.batch_solve(sample_questions)\n",
    "    \n",
    "    # Save results\n",
    "    results_df = pd.DataFrame(solutions)\n",
    "    results_df.to_csv('gsm8k_solutions.csv', index=False)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch GPU (Python 3.11)",
   "language": "python",
   "name": "pytorch-gpu-python-3-11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
